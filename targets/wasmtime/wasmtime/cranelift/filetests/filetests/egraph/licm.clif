test optimize
set opt_level=speed
target x86_64

function %f(i32, i32) -> i32 {
block0(v0: i32, v1: i32):
    jump block1(v0)

block1(v2: i32):
    v3 = iconst.i32 1
    v4 = iadd.i32 v1, v3
    v5 = iconst.i32 40
    v6 = icmp eq v2, v5
    v7 = iconst.i32 1
    v8 = iadd.i32 v2, v7
    brif v6, block2(v4), block1(v8)

block2(v9: i32):
    return v9
}

; check:  block0(v0: i32, v1: i32):
; check:      jump block1(v0)

; check:  block1(v2: i32):
;; constants are rematerialized in each block where used
; check:      v10 = iconst.i32 40
; check:      v11 = icmp eq v2, v10
; check:      v12 = iconst.i32 1
; check:      v13 = iadd v2, v12
; check:      brif v11, block2, block1(v13)


; check:  block2:
; check:      v14 = iconst.i32 1
; check:      v15 = iadd.i32 v1, v14
; check:      return v15

function %f(i64x2, i32) -> i64x2 {
block0(v0: i64x2, v1: i32):
    jump block1(v0, v1)

block1(v2: i64x2, v3: i32):
    v4 = vconst.i64x2 0x1000000010000000
    v5 = iadd v2, v4
    v6 = iconst.i32 1
    v7 = isub v3, v6
    brif v7, block1(v5, v7), block2(v5)

block2(v8: i64x2):
    return v8
}

; check:  block0(v0: i64x2, v1: i32):
; check:      v4 = vconst.i64x2 const0
; nextln:     jump block1(v0, v1)
; check:  block1(v2: i64x2, v3: i32):
; check:      v9 = iconst.i32 1
; check:      v10 = isub v3, v9
; check:      v5 = iadd v2, v4
; check:      v8 -> v5
; check:      brif v10, block1(v5, v10), block2
; check:  block2:
; check:      return v5

;; don't lift vconst out of 2 loops, only the inner loop, based on the current
;; heuristic.
function %f(i64x2, i32, i32) -> i64x2 {
block0(v0: i64x2, v1: i32, v2: i32):
    jump block1(v0, v1, v2)

block1(v3: i64x2, v4: i32, v5: i32):
    jump block2(v3, v4)

block2(v6: i64x2, v7: i32):
    v8 = vconst.i64x2 0x1000000010000000
    v9 = iadd v6, v8
    v10 = iconst.i32 1
    v11 = isub v7, v10
    brif v11, block2(v9, v11), block3(v9)

block3(v12: i64x2):
    v13 = iconst.i32 1
    v14 = isub v5, v13
    brif v14, block1(v9, v4, v14), block4

block4:
    return v12
}

; check:  block0(v0: i64x2, v1: i32, v2: i32):
; check:      jump block1(v0, v2)
; check:  block1(v3: i64x2, v5: i32):
; check:      v8 = vconst.i64x2 const0
; check:      jump block2(v3, v1)
; check:  block2(v6: i64x2, v7: i32):
; check:      v15 = iconst.i32 1
; check:      v16 = isub v7, v15
; check:      v9 = iadd v6, v8
; check:      brif v16, block2(v9, v16), block3
; check:  block3:
; check:      v17 = iconst.i32 1
; check:      v18 = isub.i32 v5, v17
; check:      brif v18, block1(v9, v18), block4
; check:  block4:
; check:      return v9

;; Don't let a rematerialized iconst inhibit (or even reverse)
;; LICM. See issue #7283.

function %f(i64, i64) {
block0(v0: i64, v1: i64):
    ;; Create a loop-invariant value `v10` which is some operation which
    ;; includes a constant somewhere.
    v8 = load.f64 v0+100
    v9 = f64const 0x1.0000000000000p1
    v10 = fdiv v8, v9

    ;; jump to the loop
    v3 = iconst.i64 0
    jump block2(v3)  ; v3 = 0

block2(v11: i64):
    ;; store the loop-invariant `v10` to memory "somewhere"
    v15 = iadd v0, v11
    store.f64 v10, v15

    ;; loop breakout condition
    v17 = iadd_imm v11, 1
    v19 = icmp_imm ne v17, 100
    brif v19, block2(v17), block1

block1:
    return
}

; check: load
; check: f64const
; check: fdiv
; check: block2(v11: i64)
; check: iadd
; check: store
; check: brif
